{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QshK8s21WBrf"
   },
   "source": [
    "# Homework08\n",
    "\n",
    "Exercises to practice unsupervised learning with clustering\n",
    "\n",
    "## Goals\n",
    "\n",
    "- Get more practice with the ML flow: encode -> normalize -> train -> evaluate\n",
    "- Understand the tradeoffs of modeling parameters\n",
    "- Develop intuition for different clustering models and when to use them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Hf8SXUwWOho"
   },
   "source": [
    "### Setup\n",
    "\n",
    "Run the following 2 cells to import all necessary libraries and helpers for this homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/PSAM-5020-2025S-A/5020-utils/raw/main/src/data_utils.py\n",
    "!wget -q https://github.com/PSAM-5020-2025S-A/5020-utils/raw/main/src/image_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from os import listdir\n",
    "from PIL import Image as PImage\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from data_utils import object_from_json_url\n",
    "from data_utils import StandardScaler\n",
    "from data_utils import KMeansClustering, GaussianClustering\n",
    "\n",
    "from image_utils import get_pixels, make_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helmet Sizing\n",
    "\n",
    "### Load Dataset\n",
    "\n",
    "Let's load up the full [ANSUR](https://www.openlab.psu.edu/ansur2/) dataset that we looked at briefly in [Week 02](https://github.com/PSAM-5020-2025S-A/WK02) and then again in [Homework06](https://github.com/PSAM-5020-2025S-A/Homework06).\n",
    "\n",
    "This is the dataset that has anthropometric information about U.S. Army personnel.\n",
    "\n",
    "#### WARNING\n",
    "\n",
    "Like we mentioned in class, this dataset is being used for these exercises due to the level of detail in the dataset and the rigorous process that was used in collecting the data.\n",
    "\n",
    "This is a very specific dataset and should not be used to draw general conclusions about people, bodies, or anything else that is not related to the distribution of physical features of U.S. Army personnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "ANSUR_FILE = \"https://raw.githubusercontent.com/PSAM-5020-2025S-A/5020-utils/main/datasets/json/ansur.json\"\n",
    "ansur_data = object_from_json_url(ANSUR_FILE)\n",
    "\n",
    "# Look at first 2 records\n",
    "ansur_data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load it into a `DataFrame`, like last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read into DataFrame\n",
    "ansur_df = pd.json_normalize(ansur_data)\n",
    "ansur_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Learning\n",
    "\n",
    "Let's pretend we are designing next-generation helmets with embedded over-the-ear headphones and we want to have a few options for sizes.\n",
    "\n",
    "We could use clustering to see if there is a number of clusters that we can divide our population into, so each size covers a similar portion of the population.\n",
    "\n",
    "We can follow similar steps to regression to create a clustering model that uses features about head and ear sizes:\n",
    "\n",
    "1. Load dataset (done! ðŸŽ‰)\n",
    "2. Encode label features as numbers\n",
    "3. Normalize the data\n",
    "4. Separate the feature variables we want to consider (done below)\n",
    "5. Pick a clustering algorithm\n",
    "6. Determine number of clusters\n",
    "7. Cluster data\n",
    "8. Interpret results\n",
    "\n",
    "For step $5$, it's fine to just pick an algorithm ahead of time to see what happens, but feel free to experiment and plot results for multiple clustering methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "## Encode non-numerical features\n",
    "# gender_encoded=[]\n",
    "# for gender in ansur_df[\"gender\"]:\n",
    "#     if(gender == 'F'):\n",
    "#         gender_encoded.append(1)\n",
    "#     else\n",
    "#         gender_encoded.append(0)\n",
    "# ansur_df[\"gender\"] =gender_encoded\n",
    "#I wrote this thing above, but this is not the elegant way to do it so I found this on chatgpt.\n",
    "\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "ansur_df['gender'] = encoder.fit_transform(ansur_df[['gender']])\n",
    "print(ansur_df['gender'])\n",
    "ansur_df.columns #lol learnt from my mistake the last time and checked it in the first go\n",
    "\n",
    "## Normalize the data\n",
    "\n",
    "ansur_scaler =StandardScaler();\n",
    "\n",
    "ansur_scaled_df = ansur_scaler.fit_transform(ansur_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Separate the features we want to consider\n",
    "ansur_features = ansur_scaled_df[[\"head.height\", \"head.circumference\", \"ear.length\", \"ear.breadth\", \"ear.protrusion\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## 6. Run the model on the data\n",
    "\n",
    "\n",
    "## Create Clustering model\n",
    "num_of_clusters =5\n",
    "km_model = KMeansClustering(n_clusters=num_of_clusters, random_state=1010)\n",
    "gs_model =GaussianClustering(n_clusters=num_of_clusters, random_state=101010)\n",
    "\n",
    "## Run the model(s) on the data\n",
    "km_predicted = km_model.fit_predict(ansur_features)\n",
    "gs_predicted = gs_model.fit_predict(ansur_features)\n",
    "## Check errors\n",
    "print(km_predicted)\n",
    "print(km_model.inertia_)\n",
    "## Plot clusters as function of 2 or 3 variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy pasted:\n",
    "def plot_clusters(features, labels, clusters, title):\n",
    "  xl, yl, zl = labels[:3]\n",
    "  x = features[xl]\n",
    "  y = features[yl]\n",
    "  z = features[zl]\n",
    "\n",
    "  # 2D\n",
    "  plt.scatter(x, y, c=clusters, marker='o', linestyle='', alpha=0.5)\n",
    "  plt.title(f\"{title} clustering\")\n",
    "  plt.xlabel(xl)\n",
    "  plt.ylabel(yl)\n",
    "  plt.ylim([-2.2, 3])\n",
    "  plt.show()\n",
    "\n",
    "  plt.scatter(x, z, c=clusters, marker='o', linestyle='', alpha=0.5)\n",
    "  plt.title(f\"{title} clustering\")\n",
    "  plt.xlabel(xl)\n",
    "  plt.ylabel(zl)\n",
    "  plt.ylim([-2.2, 3])\n",
    "  plt.show()\n",
    "\n",
    "  # 3D\n",
    "  fig = plt.figure(figsize=(8, 8))\n",
    "  ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "  ax.scatter(x, y, z, c=clusters, marker='o', linestyle='', alpha=0.5)\n",
    "\n",
    "  ax.set_title(f\"{title} clustering\")\n",
    "  ax.set_xlabel(xl)\n",
    "  ax.set_ylabel(yl)\n",
    "  ax.set_zlabel(zl)\n",
    "  ax.set_ylim(-2.5, 8)\n",
    "  ax.set_zlim(-2.5, 2.5)\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting\n",
    "labels = [\"head.height\", \"head.circumference\", \"ear.length\", \"ear.breadth\", \"ear.protrusion\"]\n",
    "clusters = km_predicted[\"clusters\"]\n",
    "\n",
    "plot_clusters(ansur_features, labels, clusters, \"K-Means\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting\n",
    "labels2 = [\"head.height\", \"head.circumference\", \"ear.length\", \"ear.breadth\", \"ear.protrusion\"]\n",
    "clusters2 = gs_predicted[\"clusters\"]\n",
    "\n",
    "plot_clusters(ansur_features, labels2, clusters2, \"GS-Means\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "Which clustering algorithm did you choose?<br>\n",
    "Did you try a different one?<br>\n",
    "Do the clusters make sense ? Do they look balanced ?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">did both..</span>\n",
    "<span style=\"color:hotpink;\">kinda feel likge GS is performing better?  But clearly not by much. they look balanced in the sence that the're equally divided, but they don't seem great in terms of how differently identified they are.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure out how many cluster\n",
    "\n",
    "Experiment with the number of clusters to see if the initial choice makes sense.\n",
    "\n",
    "The [WK08](https://github.com/PSAM-5020-2025S-A/WK08) notebook had a for loop that can be used to plot errors versus number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "## Plot errors and pick how many cluster\n",
    "print(\"KMeans balance score:\", km_model.balance_score())\n",
    "print(\"Gaussian balance score:\", gs_model.balance_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# try 2 - 10 clusters for K-Means Clustering\n",
    "num_clusters = list(range(2,10))\n",
    "\n",
    "# collect distance, silhouette and balance scores\n",
    "score_scores = []\n",
    "distance_scores = []\n",
    "silhouette_scores = []\n",
    "balance_scores = []\n",
    "\n",
    "# get distance, likelihood and balance for different clustering sizes\n",
    "for n in num_clusters:\n",
    "  mm = KMeansClustering(n_clusters=n)\n",
    "  mm.fit_predict(ansur_features)\n",
    "  score_scores.append(mm.score(ansur_features.values))\n",
    "  distance_scores.append(mm.distance_score())\n",
    "  silhouette_scores.append(mm.silhouette_score())\n",
    "  balance_scores.append(mm.balance_score())\n",
    "\n",
    "# plot scores as function of number of clusters\n",
    "plt.plot(num_clusters, score_scores, marker='o')\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Distance Squared Sum Score\")\n",
    "plt.title(\"K-means Clustering\")\n",
    "# plt.ylim([0, 3])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(num_clusters, distance_scores, marker='o')\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Distance Score\")\n",
    "plt.title(\"K-means Clustering\")\n",
    "# plt.ylim([0, 3])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(num_clusters, silhouette_scores, marker='o')\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.title(\"K-means Clustering\")\n",
    "# plt.ylim([-1, 1])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(num_clusters, balance_scores, marker='o')\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Balance Score\")\n",
    "plt.title(\"K-means Clustering\")\n",
    "plt.ylim([0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "Based on the graphs of errors versus number of clusters, does it look like we should change the initial number of clusters ?<br>\n",
    "How many clusters should we use ? Why ?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">It kinda looks like 2 clusters is the best idea here. By and large reaches a point of diminishing returns over there.</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revise Number of Clusters.\n",
    "\n",
    "Re-run with the new number of clusters and plot the data in $2D$ or $3D$.\n",
    "\n",
    "This can be the same graph as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "## Plot clusters as function of 2 or 3 variables\n",
    "num_of_clusters =2\n",
    "## Re-run clustering with final number of clusters\n",
    "\n",
    "km_model = KMeansClustering(n_clusters=num_of_clusters, random_state=1010)\n",
    "gs_model =GaussianClustering(n_clusters=num_of_clusters, random_state=101010)\n",
    "\n",
    "## Run the model on the training data\n",
    "km_predicted = km_model.fit_predict(ansur_features)\n",
    "gs_predicted = gs_model.fit_predict(ansur_features)\n",
    "\n",
    "## Check errors\n",
    "print(km_predicted)\n",
    "print(km_model.inertia_)\n",
    "## Plot in 3D\n",
    "\n",
    "labels3 = [\"head.height\", \"head.circumference\", \"ear.length\", \"ear.breadth\", \"ear.protrusion\"]\n",
    "clusters3 = gs_predicted[\"clusters\"]\n",
    "\n",
    "plot_clusters(ansur_features, labels3, clusters3, \"GS-Means\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Plot clusters as function of 2 or 3 variables\n",
    "num_of_clusters =3\n",
    "## Re-run clustering with final number of clusters\n",
    "\n",
    "km_model = KMeansClustering(n_clusters=num_of_clusters, random_state=1010)\n",
    "gs_model =GaussianClustering(n_clusters=num_of_clusters, random_state=101010)\n",
    "\n",
    "## Run the model on the training data\n",
    "km_predicted = km_model.fit_predict(ansur_features)\n",
    "gs_predicted = gs_model.fit_predict(ansur_features)\n",
    "\n",
    "## Check errors\n",
    "print(km_predicted)\n",
    "print(km_model.inertia_)\n",
    "## Plot in 3D\n",
    "\n",
    "labels3 = [\"head.height\", \"head.circumference\", \"ear.length\", \"ear.breadth\", \"ear.protrusion\"]\n",
    "clusters3 = gs_predicted[\"clusters\"]\n",
    "\n",
    "plot_clusters(ansur_features, labels3, clusters3, \"GS-Means\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Plot clusters as function of 2 or 3 variables\n",
    "num_of_clusters =2\n",
    "## Re-run clustering with final number of clusters\n",
    "\n",
    "km_model = KMeansClustering(n_clusters=num_of_clusters, random_state=1010)\n",
    "gs_model =GaussianClustering(n_clusters=num_of_clusters, random_state=101010)\n",
    "\n",
    "## Run the model on the training data\n",
    "km_predicted = km_model.fit_predict(ansur_features)\n",
    "gs_predicted = gs_model.fit_predict(ansur_features)\n",
    "\n",
    "## Check errors\n",
    "print(km_predicted)\n",
    "print(km_model.inertia_)\n",
    "## Plot in 3D\n",
    "\n",
    "labels3 = [\"head.height\", \"head.circumference\", \"ear.length\", \"ear.breadth\", \"ear.protrusion\"]\n",
    "clusters3 = km_predicted[\"clusters\"]\n",
    "\n",
    "plot_clusters(ansur_features, labels3, clusters3, \"KM-Means\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Plot clusters as function of 2 or 3 variables\n",
    "num_of_clusters =3\n",
    "## Re-run clustering with final number of clusters\n",
    "\n",
    "km_model = KMeansClustering(n_clusters=num_of_clusters, random_state=1010)\n",
    "gs_model =GaussianClustering(n_clusters=num_of_clusters, random_state=101010)\n",
    "\n",
    "## Run the model on the training data\n",
    "km_predicted = km_model.fit_predict(ansur_features)\n",
    "gs_predicted = gs_model.fit_predict(ansur_features)\n",
    "\n",
    "## Check errors\n",
    "print(km_predicted)\n",
    "print(km_model.inertia_)\n",
    "## Plot in 3D\n",
    "\n",
    "labels3 = [\"head.height\", \"head.circumference\", \"ear.length\", \"ear.breadth\", \"ear.protrusion\"]\n",
    "clusters3 = km_predicted[\"clusters\"]\n",
    "\n",
    "plot_clusters(ansur_features, labels3, clusters3, \"KM-Means\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "Do these look better than the original number of clusters?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">Yeah I think this is a lot better, the GS-model with 3 clusters especially.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Organization\n",
    "\n",
    "We have a dataset of about $600$ flower images that we might want to classify by species... eventually.\n",
    "\n",
    "What we want to do first is take a look at all of the images and see what kind of images we have, what kind of colors our flowers have and see if there's any other visual information that could help us classify these images later.\n",
    "\n",
    "We'll see how to use clustering and distances to organize our images by color to create a visualization that we cna use to get to know our dataset.\n",
    "\n",
    "### Load Dataset\n",
    "\n",
    "The following cell downloads the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -qO- https://github.com/PSAM-5020-2025S-A/5020-utils/releases/latest/download/flowers.tar.gz | tar xz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can take a look at a few of the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR = \"./data/image/flowers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(PImage.open(f\"{IMG_DIR}/00_001.png\"))\n",
    "display(PImage.open(f\"{IMG_DIR}/15_001.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Representative Colors\n",
    "\n",
    "The overall process for organizing our images by color will be something like this:\n",
    "\n",
    "1. Iterate over all files in the `data/image/flowers` directory, open each image file and treat it as a dataset\n",
    "   1. Load image into a `DataFrame` where each pixel is a row and R,G,B values are columns/features\n",
    "   2. Cluster into $2$ - $16$ colors\n",
    "   3. Pick $3$ or $4$ representative colors\n",
    "   4. Store image filenames and their representative colors in a Python object\n",
    "2. Once all images have been processed we can order our dataset by different color characteristics: white to black, red to blue, hue value, brightness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Image\n",
    "\n",
    "Let's step through the process of getting representative colors for one image, and then we can repeat this in a loop to process all of the flower images.\n",
    "\n",
    "#### Open Image\n",
    "\n",
    "The `PIL` library does all the work here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open image\n",
    "fname = \"00_001.png\"\n",
    "pimg = PImage.open(f\"{IMG_DIR}/{fname}\").convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put into `DataFrame`\n",
    "\n",
    "We get the pixels and make a dataset/`DataFrame` out of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load into DataFrame\n",
    "pxs = get_pixels(pimg)\n",
    "pxs_df = pd.DataFrame(pxs, columns=[\"R\", \"G\", \"B\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pxs_df.head\n",
    "len(pxs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pxs_df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster colors\n",
    "\n",
    "Create a clustering object, cluster colors into $8$ clusters with `fit_predict()` and take a look at our color palette (`cluster_centers_`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Create Clustering object\n",
    "num_of_clusters =4\n",
    "km_model = KMeansClustering(n_clusters=num_of_clusters, random_state=1010)\n",
    "gs_model =GaussianClustering(n_clusters=num_of_clusters, random_state=101010)\n",
    "# TODO: Cluster by color\n",
    "km_predicted = km_model.fit_predict(pxs_df[[\"R\", \"G\", \"B\"]])\n",
    "gs_predicted = gs_model.fit_predict(pxs_df[[\"R\", \"G\", \"B\"]])\n",
    "\n",
    "# TODO: Take a look at the color palette (cluster_centers_)\n",
    "\n",
    "print(km_model.cluster_centers_)\n",
    "print(gs_model.cluster_centers_)\n",
    "# plot_clusters(pxs_df, [\"R\", \"G\", \"B\"], km_predicted[\"clusters\"], \"KM-Means\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pxs_df[\"cluster_id\"] = km_predicted[\"clusters\"]\n",
    "\n",
    "print(pxs_df.columns)\n",
    "print(pxs_df[\"cluster_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "Does anything stand out about the colors?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">Red is dominant, clearly. there is a dark grey, a maroon-ish, and a brown?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconstruct Image\n",
    "\n",
    "Since we're only doing one image for now, let's take a look at the clustering result.\n",
    "\n",
    "This is like in the lecture notebook. We'll start with an empty pixel array and as we iterate through the `DataFrame` of cluster ids we append the corresponding colors to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: create empty pixel array\n",
    "\n",
    "\n",
    "# TODO: iterate through resulting list of cluster ids\n",
    "# for pixel_iterator, pixel in enumerate(pxs_df):\n",
    "#      # pxs_post.append(color for color in km_model.cluster_centers_ where )\n",
    "\n",
    "#      #but for this to work cluster has to be the id. it's just 0-7, but the same 0-7 should be in \n",
    "#      for cluster_iterator, cluster in enumerate(km_model.cluster_centers_): # so this is just going through all 8 at the moment\n",
    "#           if(cluster_iterator == pxs_df[pixel_iterator][\"cluster_id\"]): #only looking at all the pixels which fall under that one cluster rn\n",
    "#                 pxs_post.append(cluster) #so now I have the actual rgb values, appended\n",
    "# this is my code and thinking above, didn't work, got help from chatgpt for the part below, it explained that I can't iterate over the columns of the dataframe(which is what I was doing and should be iterating over the pixels instead using the iterrows() function instead)\n",
    "\n",
    "# TODO: append corresponding color value to pixel array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each row in pxs_df using iterrows()\n",
    "pxs_post = []  # Your empty list to store RGB values\n",
    "\n",
    "# Iterate over each row in pxs_df using iterrows()\n",
    "for _, row in pxs_df.iterrows():\n",
    "    # Get the cluster ID for the current pixel\n",
    "    cluster_id = row[\"cluster_id\"]\n",
    "\n",
    "    # Get the RGB value of the current cluster from cluster_centers_\n",
    "    cluster_rgb = km_model.cluster_centers_[cluster_id]\n",
    "\n",
    "    # Convert the RGB values to integers\n",
    "    cluster_rgb_int = [int(channel) for channel in cluster_rgb]\n",
    "\n",
    "    # Append the RGB value (now as integers) to the pxs_post list\n",
    "    pxs_post.append(cluster_rgb_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pxs_post))  # Should be total number of pixels in the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can look at the image. If this next cell gives errors about using `float` values in images, just make sure the pixel values that are being appended above are all whole number `int` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(make_image(pxs_post, width=pimg.size[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "How does changing the number of clusters affect the resulting image?<br>Try some lower values like <code>2</code> and <code>4</code>, and also some higher ones like <code>12</code> and <code>16</code>. Take a look at a different image.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">well, I don't know what I did wrong but I didn't even get an image with just 2 clusters.</span>\n",
    "\n",
    "<span style=\"color:hotpink;\">nevermind, it was some error that has just made the whole thing a whole lot fainter, I probably messed witht he alphas.</span>\n",
    "\n",
    "<span style=\"color:hotpink;\">Okay, I have no idea what messed this up. I tried some things to fix it, didnt work. But I see the faint images in different colours, and that's that BECAUSE BEFORE I CHANGED IT TO 2 CLUSTERS IT WORKED PERFECTLY ONCE AND HOPEFULLY THATS ENOUGH</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pick Colors\n",
    "\n",
    "Ok, we have some representative colors for our images. We should keep more than one color, but maybe we don't have to keep $12$.\n",
    "\n",
    "We can use the `value_counts()` function of our `DataFrame` to see how many pixels are represented by each of our cluster colors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster ids and pixel counts, ordered by descending counts\n",
    "\n",
    "ccounts = pxs_df[\"cluster_id\"].value_counts()\n",
    "display(ccounts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since what we are really trying to do here is get some information about the colors of the flowers present in our images, and given the type of images we have, we can start by assuming that the flower colors will be in the top-$4$ clusters returned by `value_counts()`.\n",
    "\n",
    "We can revisit this assumption later. We might also want to add some filters here to ignore sky and vegetation colors (blues and greens) and only keep flower colors.\n",
    "\n",
    "For now, let's just grab the top-$4$ colors from `value_counts()`, remembering we want to keep their rounded `int` values and not the default `float` values in `cluster_centers_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# List to keep colors for each file\n",
    "file_colors = [None] * 4 \n",
    "\n",
    "\n",
    "# TODO: go through ccounts.index and get corresponding colors for clusters\n",
    "for index in ccounts.index:\n",
    "    file_colors[index] = km_model.cluster_centers_[cluster_id]\n",
    "\n",
    "    \n",
    "\n",
    "# TODO: add top-3 colors to the file_colors object\n",
    "file_colors = file_colors[1:]\n",
    "print(file_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each row in pxs_df using iterrows()\n",
    "pxs_post = []  # Your empty list to store RGB values\n",
    "\n",
    "# Iterate over each row in pxs_df using iterrows()\n",
    "for _, row in pxs_df.iterrows():\n",
    "    # Get the cluster ID for the current pixel\n",
    "    cluster_id = row[\"cluster_id\"]\n",
    "\n",
    "    # Get the RGB value of the current cluster from cluster_centers_\n",
    "    cluster_rgb = km_model.cluster_centers_[cluster_id]\n",
    "\n",
    "    # Convert the RGB values to integers\n",
    "    cluster_rgb_int = [int(channel) for channel in cluster_rgb]\n",
    "\n",
    "    # Append the RGB value (now as integers) to the pxs_post list\n",
    "    pxs_post.append(cluster_rgb_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(file_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "Why might we want to cluster into <code>8</code> or even <code>12</code> colors when in the end we're only keeping <code>4</code>?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">gets the nuances of the image better? I'm just guessing, but the separation is probably cleaner--because we're clustering into a larger number but then ordering the clusters--so the ordering probably would be less significant in 4 clusters directly. More likely to turn up as lower contrast colours rather than capturing more contrast. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate and Cluster\n",
    "\n",
    "We've processed one image, now let's process $600$... for-loops FTW!\n",
    "\n",
    "We'll need to loop through all of the images in our directory and repeat the process above for each one of them.\n",
    "\n",
    "We can create a function that takes a filename as input and returns the top-$4$ colors for that image, or... we can just put all of the clustering logic in the body of a for loop. Whichever is easiest.\n",
    "\n",
    "Let's get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all files in the flowers directory\n",
    "flower_files = sorted([f for f in listdir(IMG_DIR) if f.endswith(\".png\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the loop. In the end we want our `file_colors` list to have objects that have a filename and $4$ colors associated with each filename. Something like:\n",
    "\n",
    "```py\n",
    "[\n",
    "  {\n",
    "    \"filename\": \"00_001.png\",\n",
    "    \"colors\": [[12,44,12], [112,144,62],  [12,84,112], [212,144,102]]\n",
    "  },\n",
    "  {\n",
    "    \"filename\": \"00_002.png\",\n",
    "    \"colors\": [[22,24,28], [112,114,122], [128,200,2], [250,240,230]]\n",
    "  },\n",
    "  ...\n",
    "]\n",
    "```\n",
    "\n",
    "This can take a while to run (up to a minute for $600$ images). We can use slicing to test our logic on a subset of `flower_files` before processing all $600$ images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# List to keep colors for each file\n",
    "file_colors = []\n",
    "\n",
    "# TODO: get colors for each image\n",
    "for fname in flower_files:\n",
    "  # TODO: add logic here\n",
    "  pimg = PImage.open(f\"{IMG_DIR}/{fname}\").convert(\"RGB\")\n",
    "  pxs = get_pixels(pimg)\n",
    "  pixels_df = pd.DataFrame(pxs, columns=[\"R\", \"G\", \"B\"])\n",
    "\n",
    "  number_of_Clusters = 8\n",
    "  km_model =KMeansClustering(n_clusters=number_of_Clusters, random_state=1010)\n",
    "  predicted_km = km_model.fit_predict(pixels_df[[\"R\", \"G\", \"B\"]])\n",
    "  pixels_df[\"cluster_id\"] = predicted_km[\"clusters\"]\n",
    "\n",
    "  ccounts = pixels_df[\"cluster_id\"].value_counts()\n",
    "  top_clusters = ccounts.index[:4]\n",
    "  \n",
    "\n",
    "  file_colors_img = [list(map(int, km_model.cluster_centers_[cid])) for cid in top_clusters]\n",
    "\n",
    "\n",
    "  \n",
    "    # TODO: add filename+colors object to list of objects\n",
    "  file_colors.append({\n",
    "    \"filename\": fname,\n",
    "    \"colors\": file_colors_img\n",
    "  })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(file_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it has been going for 17 minutes and I am afraid that it is going to crash.\n",
    "#ok the problem was  gaussian, I tried with k-means and it took much lesser time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order Images (almost)\n",
    "\n",
    "We have a list with objects that keep track of filenames and representative colors. We could create a `DataFrame` or csv dataset with these, but let's go ahead and just use this directly in this format.\n",
    "\n",
    "What we want to do is re-order our list of objects, but using a `key` function that takes each object's colors into consideration.\n",
    "\n",
    "We'll look into how to do this dynamically later, but for now let's order our images by something like _brightness_. It's _like_ brightness because what we'll do is measure how close each image is to the white color `(255,255,255)`.\n",
    "\n",
    "We'll need some helper functions first:\n",
    "\n",
    "- `color_distance()`: takes $2$ colors and returns the distance between them\n",
    "- `min_color_distance()`: given a reference color and a list of colors, returns the distance between the reference color and the closest color in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: implement function that returns distance between two colors\n",
    "def color_distance(c0, c1):\n",
    "  return math.sqrt((c0[0] - c1[0])**2 + (c0[1] - c1[1])**2 + (c0[2] - c1[2])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some tests for the `color_distance()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some tests for the color_distance() function\n",
    "print(color_distance([0,0,0], [255,255,255]), \"should be\", 255*3**.5)\n",
    "print(color_distance([0,100,0], [100,100,0]), \"should be\", 100)\n",
    "print(color_distance([55,222,120], [91,51,192]), \"should be\", 189)\n",
    "print(color_distance([147,207,246], [87,57,50]), \"should be\", 254)\n",
    "print(color_distance([12,250,126], [112,10,195]), \"should be\", 269)\n",
    "print(color_distance([106,71,61], [105,136,100]), \"should be\", 75.81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: implement function that returns minimum distance between a reference color and colors from a list\n",
    "def min_color_distance(ref_color, color_list):\n",
    "  # TODO: add logic here\n",
    "  full_distances =[]\n",
    "  for colour in color_list:\n",
    "    full_distances.append(color_distance(ref_color, colour))\n",
    "  return min(full_distances)\n",
    "# TODO: Change this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three tests for the `min_color_distance()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some tests for the color_distance() function\n",
    "print(min_color_distance([0,0,0], [[255,255,255],[0,100,0],[100,100,0],[58,58,58]]), \"should be\", 100)\n",
    "print(min_color_distance([0,0,0], [[255,255,255],[0,100,0],[100,100,0],[58,57,58]]), \"should be\", 99.88)\n",
    "print(min_color_distance([91,51,192], [[147,207,246],[87,57,50],[12,250,126],[112,10,195]]), \"should be\", 46.16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order Images (for real now)\n",
    "\n",
    "Alright. We have a function that can be used to order our images by their distance to a given color.\n",
    "\n",
    "Let's order our images by how close they are to the brightest color `(255,255,255)`. We'll define a `key` function that, given an object from our `file_colors` list, returns how close that image is to the color `(255,255,255)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: implement function that returns how close our image is to the color white\n",
    "def by_bright_dist(A):\n",
    "    white_color = [255, 255, 255]\n",
    "    distances = [color_distance(white_color, pixel) for pixel in A]\n",
    "    return sum(distances) / len(distances)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order the list and write out a `JSON` file with the image order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_colors_sorted = sorted(file_colors, key=by_bright_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_sorted = [A[\"filename\"] for A in file_colors_sorted]\n",
    "\n",
    "with open(\"./data/flower_order.json\", \"w\") as ofp:\n",
    "  json.dump(files_sorted, ofp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Results\n",
    "\n",
    "We can check the results by running a webserver and looking at a simple web page that orders the images according to the resulting `JSON` file from above.\n",
    "\n",
    "We'll make use of the [`Live Server`](https://marketplace.visualstudio.com/items?itemName=ritwickdey.LiveServer) VSCode extension.\n",
    "\n",
    "We can start the server by clicking on the \"_Go Live_\" button towards the right hand side of the bar at the very bottom of our text editor:\n",
    "\n",
    "<img src=\"./imgs/go_live.jpg\" width=\"600px\">\n",
    "\n",
    "Clicking the \"_Go Live_\" button in Codespace should open up a new tab with a plain html navigation view of our repository. Clicking on the `html/` directory should open up a web page with all of the flower images. If not, you can use your Codespace url to try to find the web server address.\n",
    "\n",
    "If your Codespace url is something like:<br>`https://mango-special-giggle-v6v7asd322f7p6.github.dev/`\n",
    "\n",
    "Then, the webserver should be running at:<br>`https://mango-special-giggle-v6v7asd322f7p6-5500.app.github.dev/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review, Contemplate, Experiment\n",
    "\n",
    "Yes, images with white parts are towards the beginning, but the images towards the end aren't necessarily the ones with dark flowers, but are the ones that have all of their representative colors farthest away from white `(255,255,255)`, which includes very saturated colors/images.\n",
    "\n",
    "A couple of interesting experiments here could be:\n",
    "- Decrease the number of clusters or the number of colors kept after clustering.\n",
    "- Use different colors as the reference for the distance functions. For example, create `by_gold_dist()` or `by_purple_dist()` functions to use as the `key` for sorting.\n",
    "- Order the list of cluster colors by [hue](https://stackoverflow.com/questions/23090019/fastest-formula-to-get-hue-from-rgb). This can be a bit tricky to get right because some colors, like white, black and gray, don't have a unique value for hue, but depend on other aspects of the color, like saturation and lightness, to be well-defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: experiment with number of clusters, number of colors, reference colors or hue distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "What did you try ? What happened ?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">EDIT THIS CELL WITH ANSWER</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "It's challenging to define a set of functions that will perfectly order our flowers by color without first having to define very specific color values for filtering and corner-cases. At a high-level, we can imagine that this is because color is a $3$-dimensional value, and we're using it to organize our images into a single-dimensional order.\n",
    "\n",
    "The beginning of our ordering is usually pretty good, since there's only one way for a color to be _close_ to our reference color, but the ordering gets less consistent towards the end because there are many different ways for a color to be _far_ from the reference color.\n",
    "\n",
    "Next week we'll see a very powerful technique that, amongst other things, will help us get around this kind of \"_dimensionality mismatch_\"."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPxe2qYxIG7EblrvD1C4Pmv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
